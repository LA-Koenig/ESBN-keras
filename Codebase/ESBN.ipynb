{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4636998e-861c-4f42-9bfe-d937613a6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4c4c-a3c6-492e-bfdd-72e63d6db718",
   "metadata": {},
   "source": [
    "This is following the model from LucidRains with some advisement from the original code\n",
    "\n",
    "https://github.com/lucidrains/ESBN-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e65ffde-5065-4082-8678-b029e04c2514",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de49f2c8-54ab-4771-ae9e-8b7f70339371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3282cc68-2d34-4a86-b38b-09f9c64c7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_cat(t, el, dim =0):\n",
    "    if not exists(t):\n",
    "        return el\n",
    "    return tf.concat((t, el), axis = dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1654469-6e43-46f8-8a6b-d556302d3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_fn(fn, *args, **kwargs):\n",
    "    def inner(*arr):\n",
    "        return map(lambda t: fn(t, *args, **kwargs), arr)\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3cccdb-fc02-49c9-aa09-9e5fea9de15b",
   "metadata": {},
   "source": [
    "# the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f5311f-3fff-4339-9d23-75dac39fd432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESBN(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        value_dim = 64,\n",
    "        key_dim = 64,\n",
    "        hidden_dim = 512,\n",
    "        output_dim = 4,\n",
    "        encoder = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.h0 = tf.zeros(hidden_dim)\n",
    "        self.c0 = tf.zeros(hidden_dim)\n",
    "        self.k0 = tf.zeros(key_dim + 1)\n",
    "        \n",
    "        self.rnn = tf.keras.layers.LSTMCell(hidden_dim)  #What is the difference between this and just LSTM\n",
    "        self.to_gate = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) #?\n",
    "        self.to_key = tf.keras.layers.Dense(key_dim)\n",
    "        self.to_output = tf.keras.layers.Dense(output_dim)\n",
    "        \n",
    "        self.encoder = tf.keras.Sequential()\n",
    "        self.encoder.add(tf.keras.layers.Conv2D(32, kernel_size=4, strides=2, \n",
    "                                                activation=tf.keras.activations.relu))\n",
    "        self.encoder.add(tf.keras.layers.Conv2D(64, kernel_size=4, strides=2,\n",
    "                                                activation=tf.keras.activations.relu))\n",
    "        self.encoder.add(tf.keras.layers.Conv2D(64, kernel_size=4, strides=2,\n",
    "                                                activation=tf.keras.activations.relu))\n",
    "        self.encoder.add(tf.keras.layers.Flatten())\n",
    "        self.encoder.add(tf.keras.layers.Dense(value_dim))\n",
    "                         # if not exists(encoder) else encoder What does???\n",
    "            \n",
    "        self.to_confidence = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        b = images.shape[1]\n",
    "        Mk = None\n",
    "        Mv = None\n",
    "        \n",
    "        hx, cx, kx, k0 = map_fn(repeat, 'd -> b d', b = b)(self.h0, self.c0, self.k0, self.k0)\n",
    "        out =[] #note, there could be issues with lists. aslo consider a better way becaues other languages bla bla\n",
    "        \n",
    "        for ind, image in enumerate(images):\n",
    "            is_first = ind == 0\n",
    "            z = self.encoder(image)\n",
    "            hx, cx = self.rnn(kx, (hx, cx)) #return state?\n",
    "            y, g, kw = self.to_output(hx), self.to_gate(hx), self.to_key(hx)\n",
    "            \n",
    "            # if is_first: #redundent?\n",
    "            #     kx = k0\n",
    "            # else:\n",
    "            if not is_first:\n",
    "                # attention\n",
    "                sim = tf.keras.layers.EinsumDense('b n d, b d -> b n',\n",
    "                                                  activations=tf.keras.activations.linear)([Mv, z])\n",
    "                wk = tf.keras.layers.Activation(activation=tf.keras.activations.softmax)(sim)\n",
    "                # sim = tf.einsum('b n d, b d -> b n', Mv, z)\n",
    "                # wk = sim.tf.softmax(-1) #????\n",
    "                \n",
    "                # calculate confidence\n",
    "                sim, wk = map_fn(rearrange, 'b n -> b n ()')(sim, wk) #consider\n",
    "                ck = self.to_confidence(sim)\n",
    "                \n",
    "                #kx = g.sigmoid() * (wk * torch.cat((Mk, ck), dim = -1)).sum(dim = 1)\n",
    "                #g already has the sigmoid attached\n",
    "                #make a cat layer\n",
    "                #lambda layer to do the sum\n",
    "                #be careful\n",
    "                #another for the \n",
    "                cc = tf.keras.layers.concatenate([Mk, ck], axis=-1) #verified to work the same\n",
    "                cc = tf.math.reduce_sum(wk * cc, axis = 1) #same as torch.sum\n",
    "                kx = g * cc\n",
    "                \n",
    "            kw, z = map_fn(rearrange, 'b d -> b () d')(kw, z)\n",
    "            Mk = safe_cat(Mk, kw, dim = 1)\n",
    "            Mv = safe_cat(Mv, z, dim = 1)\n",
    "            out.append(y)\n",
    "            \n",
    "        return tf.stack(out) #because this is a list of tensors it should work\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70066a3-cb25-4719-8859-656b3956b9ce",
   "metadata": {},
   "source": [
    "# Same-Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "455fac36-4651-4157-85c4-f59b22e0c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is all part of the args mess in their code\n",
    "#initially setting this to be theri defaults\n",
    "\n",
    "#Model Settings\n",
    "model_name = 'ESBN'\n",
    "norm_type = 'contextnorm'\n",
    "encoder = 'conv'\n",
    "#Task settings\n",
    "task = 'same_diff'\n",
    "train_gen_mathod = 'full_space'\n",
    "n_shapes = 100 #total num of shapes available for training/testing\n",
    "m_holdout = 0 #number of objects (out of n) withheld during training\n",
    "#Training Settings\n",
    "train_batch_size = 32\n",
    "train_set_size = 10000\n",
    "train_proportion = 0.95\n",
    "lr = 5e-4\n",
    "epochs = 50\n",
    "log_interval = 10\n",
    "#Test settings\n",
    "test_batch_size = 100\n",
    "test_set_size = 10000\n",
    "#Device Settings\n",
    "no_cuda = False #Actions??? 'store_true'\n",
    "device = 0 \n",
    "#run number\n",
    "run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77089001-151a-4d8e-9fc0-4d3c0346c97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 16, 50, 74, 25, 99,  0, 65, 89, 91, 73,  1, 30, 64,  9, 48, 38,\n",
       "       39, 21, 77, 79, 46, 90, 44, 40, 22, 31, 70, 80, 87, 26, 36, 81, 53,\n",
       "       35, 69, 83, 17, 78, 75, 66, 32, 52, 33, 47, 57, 49, 51, 94, 14, 98,\n",
       "       42, 92, 54, 76, 27, 56, 45, 59,  5, 85, 72, 18, 84, 93, 97, 55, 63,\n",
       "        2, 11, 15, 12, 13, 71, 34, 58, 37, 19, 62, 86,  8, 61, 29, 41, 24,\n",
       "       23, 60, 43, 88, 28,  3,  6,  7, 82, 67, 96, 20,  4, 95, 68])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_shapes = np.arange(n_shapes)\n",
    "np.random.shuffle(all_shapes)\n",
    "all_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c044b016-27b4-4551-b9cf-2a4151330cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(m_holdout > 0):\n",
    "    train_shapes = all_shapes[m_holdout:]\n",
    "    test_shapes = all_shapes[:m_holdout]\n",
    "else:\n",
    "    train_shapes = all_shapes\n",
    "    test_shapes = all_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a337030-5dca-41bf-a589-1a39d774eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we're in their function\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Prevent python from saving out .pyc files\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "y_dim = 2\n",
    "seq_len = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "942ff480-5d9f-4fde-9f26-8626a91d1a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If m = 0, training and test sets are drawn from same set of shapes\n",
    "if(m_holdout == 0):\n",
    "    # Total number of possible trials\n",
    "    shapes_avail = n_shapes\n",
    "    total_trials = (shapes_avail * (shapes_avail - 1)) * 2\n",
    "    \n",
    "    # Proportion of training set size vs test set size\n",
    "    test_proportion = 1 - train_proportion\n",
    "    \n",
    "    # Create training/test set sizes\n",
    "    train_set_size = np.round(train_proportion * total_trials).astype(int)\n",
    "    test_set_size = np.round(test_proportion * total_trials).astype(int)\n",
    "    \n",
    "else: \n",
    "    # Ensure that there are enough potential trials for desired training set size (or change train set size)\n",
    "    shapes_avail = n_shapes - m_holdout\n",
    "    total_trials = (shapes_avail * (shapes_avail - 1)) * 2\n",
    "    \n",
    "    if(train_set_size > total_trials):\n",
    "        train_set_size = total_trials\n",
    "    \n",
    "    # Ensure that there are enough potential trials for desired test set size (or change test set size)\n",
    "    shapes_avail = n_shapes - (n_shapes - m_holdout)\n",
    "    total_trials = (shapes_avail * (shapes_avail - 1)) * 2\n",
    "    \n",
    "    if(test_set_size > total_trials):\n",
    "        test_set_size = total_trials\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "911c61a0-4b07-43bc-bc19-3164d7394f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If m = 0, training and test sets are drawn from same set of shapes\n",
    "if m_holdout == 0:\n",
    "    # Create all possible trials\n",
    "    same_trials = []\n",
    "    diff_trials = []\n",
    "    for shape1 in train_shapes:\n",
    "        for shape2 in train_shapes:\n",
    "            if shape1 == shape2:\n",
    "                same_trials.append([shape1, shape2])\n",
    "            else:\n",
    "                diff_trials.append([shape1, shape2])\n",
    "    # Shuffle\n",
    "    random.shuffle(same_trials)\n",
    "    random.shuffle(diff_trials)\n",
    "    # Split trials for train and test sets\n",
    "    same_trials_train = same_trials[:np.round(train_proportion * len(same_trials)).astype(int)]\n",
    "    same_trials_test = same_trials[np.round(train_proportion * len(same_trials)).astype(int):]\n",
    "    diff_trials_train = diff_trials[:np.round(train_proportion * len(diff_trials)).astype(int)]\n",
    "    diff_trials_test = diff_trials[np.round(train_proportion * len(diff_trials)).astype(int):]\n",
    "# Otherwise, training and test sets are completely disjoint (in terms of the shapes that are used), and can be generated separately\n",
    "else:\n",
    "    # Create all possible training trials\n",
    "    same_trials_train = []\n",
    "    diff_trials_train = []\n",
    "    for shape1 in train_shapes:\n",
    "        for shape2 in train_shapes:\n",
    "            if shape1 == shape2:\n",
    "                same_trials_train.append([shape1, shape2])\n",
    "            else:\n",
    "                diff_trials_train.append([shape1, shape2])\n",
    "    # Shuffle\n",
    "    random.shuffle(same_trials_train)\n",
    "    random.shuffle(diff_trials_train)\n",
    "    # Create all possible test trials\n",
    "    same_trials_test = []\n",
    "    diff_trials_test = []\n",
    "    for shape1 in test_shapes:\n",
    "        for shape2 in test_shapes:\n",
    "            if shape1 == shape2:\n",
    "                same_trials_test.append([shape1, shape2])\n",
    "            else:\n",
    "                diff_trials_test.append([shape1, shape2])\n",
    "    # Shuffle\n",
    "    random.shuffle(same_trials_test)\n",
    "    random.shuffle(diff_trials_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3511877e-acc2-4a90-a630-7249ff16b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate 'same' trials to match number of 'different' trials\n",
    "same_trials_train_balanced = []\n",
    "for t in range(len(diff_trials_train)):\n",
    "    same_trials_train_balanced.append(same_trials_train[np.floor(np.random.rand()*len(same_trials_train)).astype(int)])\n",
    "same_trials_test_balanced = []\n",
    "for t in range(len(diff_trials_test)):\n",
    "    same_trials_test_balanced.append(same_trials_test[np.floor(np.random.rand()*len(same_trials_test)).astype(int)])\n",
    "# Combine all same and different trials for training set\n",
    "all_train_seq = []\n",
    "all_train_targ = []\n",
    "for t in range(len(same_trials_train_balanced)):\n",
    "    all_train_seq.append(same_trials_train_balanced[t])\n",
    "    all_train_targ.append(0)\n",
    "for t in range(len(diff_trials_train)):\n",
    "    all_train_seq.append(diff_trials_train[t])\n",
    "    all_train_targ.append(1)\n",
    "# Combine all same and different trials for test set\n",
    "all_test_seq = []\n",
    "all_test_targ = []\n",
    "for t in range(len(same_trials_test_balanced)):\n",
    "    all_test_seq.append(same_trials_test_balanced[t])\n",
    "    all_test_targ.append(0)\n",
    "for t in range(len(diff_trials_test)):\n",
    "    all_test_seq.append(diff_trials_test[t])\n",
    "    all_test_targ.append(1)\n",
    "# Shuffle trials in training set\n",
    "train_ind = np.arange(len(all_train_seq))\n",
    "np.random.shuffle(train_ind)\n",
    "all_train_seq = np.array(all_train_seq)[train_ind]\n",
    "all_train_targ = np.array(all_train_targ)[train_ind]\n",
    "# Shuffle trials in test set\n",
    "test_ind = np.arange(len(all_test_seq))\n",
    "np.random.shuffle(test_ind)\n",
    "all_test_seq = np.array(all_test_seq)[test_ind]\n",
    "all_test_targ = np.array(all_test_targ)[test_ind]\n",
    "# Select subset if desired dataset size is smaller than number of all possible trials\n",
    "if (train_set_size + test_set_size) < total_trials:\n",
    "    all_train_seq = all_train_seq[:train_set_size, :]\n",
    "    all_train_targ = all_train_targ[:train_set_size]\n",
    "    all_test_seq = all_test_seq[:test_set_size, :]\n",
    "    all_test_targ = all_test_targ[:test_set_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca113dbb-26b3-4ea7-8b1d-7e1b9534c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "train_set = {'seq_ind': all_train_seq, 'y': all_train_targ}\n",
    "test_set = {'seq_ind': all_test_seq, 'y': all_test_targ}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45bea5d9-7397-4f69-a907-ec6da1b64fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#back to train and eval at line 197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92d10c7-d5f1-4d4f-bef9-40e6bdb81b00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
