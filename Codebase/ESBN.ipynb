{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4636998e-861c-4f42-9bfe-d937613a6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb4c4c-a3c6-492e-bfdd-72e63d6db718",
   "metadata": {},
   "source": [
    "This is following the model from LucidRains with some advisement from the original code\n",
    "\n",
    "https://github.com/lucidrains/ESBN-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e65ffde-5065-4082-8678-b029e04c2514",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de49f2c8-54ab-4771-ae9e-8b7f70339371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3282cc68-2d34-4a86-b38b-09f9c64c7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_cat(t, el, dim =0):\n",
    "    if not exists(t):\n",
    "        return el\n",
    "    return tf.concat((t, el), axis = dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1654469-6e43-46f8-8a6b-d556302d3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_fn(fn, *args, **kwargs):\n",
    "    def inner(*arr):\n",
    "        return map(lambda t: fn(t, *args, **kwargs), arr)\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3cccdb-fc02-49c9-aa09-9e5fea9de15b",
   "metadata": {},
   "source": [
    "# the Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f5311f-3fff-4339-9d23-75dac39fd432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESBN(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        value_dim = 64,\n",
    "        key_dim = 64,\n",
    "        hidden_dim = 512,\n",
    "        output_dim = 4,\n",
    "        encoder = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.h0 = tf.zeros(hidden_dim)\n",
    "        self.c0 = tf.zeros(hidden_dim)\n",
    "        self.k0 = tf.zeros(key_dim + 1)\n",
    "        \n",
    "        self.rnn = tf.keras.layers.LSTMCell(hidden_dim)  #What is the difference between this and just LSTM\n",
    "        self.to_gate = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) #?\n",
    "        self.to_key = tf.keras.layers.Dense(key_dim)\n",
    "        self.to_output = tf.keras.layers.Dense(output_dim)\n",
    "        \n",
    "        self.encoder = tf.keras.Sequential()\n",
    "        self.encoder.add(tf.keras.layers.Conv2D(32, kernel_size=4, strides=2, \n",
    "                                                activation=tf.keras.activations.relu))\n",
    "        self.encoder.add(tf.keras.layers.Conv2D(64, kernel_size=4, strides=2,\n",
    "                                                activation=tf.keras.activations.relu))\n",
    "        self.encoder.add(tf.keras.layers.Conv2D(64, kernel_size=4, strides=2,\n",
    "                                                activation=tf.keras.activations.relu))\n",
    "        self.encoder.add(tf.keras.layers.Flatten())\n",
    "        self.encoder.add(tf.keras.layers.Dense(value_dim))\n",
    "                         # if not exists(encoder) else encoder What does???\n",
    "            \n",
    "        self.to_confidence = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        b = images.shape[1]\n",
    "        Mk = None\n",
    "        Mv = None\n",
    "        \n",
    "        hx, cx, kx, k0 = map_fn(repeat, 'd -> b d', b = b)(self.h0, self.c0, self.k0, self.k0)\n",
    "        out =[] #note, there could be issues with lists. aslo consider a better way becaues other languages bla bla\n",
    "        \n",
    "        for ind, image in enumerate(images):\n",
    "            is_first = ind == 0\n",
    "            z = self.encoder(image)\n",
    "            hx, cx = self.rnn(kx, (hx, cx)) #return state?\n",
    "            y, g, kw = self.to_output(hx), self.to_gate(hx), self.to_key(hx)\n",
    "            \n",
    "            # if is_first: #redundent?\n",
    "            #     kx = k0\n",
    "            # else:\n",
    "            if not is_first:\n",
    "                # attention\n",
    "                sim = tf.keras.layers.EinsumDense('b n d, b d -> b n',\n",
    "                                                  activations=tf.keras.activations.linear)([Mv, z])\n",
    "                wk = tf.keras.layers.Activation(activation=tf.keras.activations.softmax)(sim)\n",
    "                # sim = tf.einsum('b n d, b d -> b n', Mv, z)\n",
    "                # wk = sim.tf.softmax(-1) #????\n",
    "                \n",
    "                # calculate confidence\n",
    "                sim, wk = map_fn(rearrange, 'b n -> b n ()')(sim, wk) #consider\n",
    "                ck = self.to_confidence(sim)\n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9bf35-b0ac-464c-b4c4-b27a7d5ad2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
